{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import os\n",
    "import patchify\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.feature_extraction import image as skimg\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from torchvision.models import resnet50, ResNet50_Weights, ResNet101_Weights\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN_ResNet50_FPN_V2_Weights,MaskRCNN_ResNet50_FPN_Weights\n",
    "import torch.optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.insert(1, '/home/prakharug/AFO')\n",
    "sys.path.insert(1, '/home/prakharug/AFO/pycoco')\n",
    "from pycoco.engine import train_one_epoch, evaluate\n",
    "import miou_eval as mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dims(a, start=0, count=2):\n",
    "    \"\"\" Reshapes numpy array a by combining count dimensions, \n",
    "        starting at dimension index start \"\"\"\n",
    "    s = a.shape\n",
    "    return np.reshape(a, s[:start] + (-1,) + s[start+count:])\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalm(model,fintestloader):\n",
    "    model.eval()\n",
    "    iou = 0\n",
    "    cnt = 0\n",
    "    for i, data in enumerate(fintestloader, 0):\n",
    "        images, targets = data\n",
    "        #print(type(targets))\n",
    "        if(images[0]==\"Problem\"):\n",
    "            continue\n",
    "        #print(type(images[0]))\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        #print(model(images)[0][\"masks\"].squeeze().shape,targets[0][\"masks\"].shape)\n",
    "        tiou,tcnt = mi.miou_eval(targets[0][\"masks\"],(model(images)[0][\"masks\"].squeeze(1)>0.5))\n",
    "        #print(tiou/tcnt)\n",
    "        #print(\"Txnt: \",tcnt)\n",
    "        del images,targets\n",
    "        iou += tiou\n",
    "        cnt += tcnt\n",
    "        #print(iou/cnt)\n",
    "    print(\"mIoU on test is:\",iou.item()/cnt)\n",
    "    model.train()\n",
    "    return iou.item()/cnt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalmt(model,fintestloader):\n",
    "    model.eval()\n",
    "    iou = 0\n",
    "    cnt = 0\n",
    "    for i, data in enumerate(fintestloader, 0):\n",
    "        images, targets = data\n",
    "        seq2 = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5), # horizontal flips\n",
    "        # Strengthen or weaken the contrast in each image.\n",
    "        iaa.LinearContrast((0.75, 1.5))],\n",
    "        random_order=True) \n",
    "        #print(type(targets))\n",
    "        if(images[0]==\"Problem\"):\n",
    "            continue\n",
    "        images1 = seq2(images=images)\n",
    "        images2 = seq2(images=images)\n",
    "        images3 = seq2(images=images)\n",
    "        #print(type(images[0]))\n",
    "        images = list(image.to(device) for image in images)\n",
    "        images1 = list(image.to(device) for image in images1)\n",
    "        images2 = list(image.to(device) for image in images2)\n",
    "        images3 = list(image.to(device) for image in images3)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        #print(model(images)[0][\"masks\"].squeeze().shape,targets[0][\"masks\"].shape)\n",
    "        tiou,tcnt = mi.miou_eval(targets[0][\"masks\"],(model(images)[0][\"masks\"].squeeze(1)>0.5))\n",
    "        tiou1,tcnt1 = mi.miou_eval(targets[0][\"masks\"],(model(images1)[0][\"masks\"].squeeze(1)>0.5))\n",
    "        tiou2,tcnt2 = mi.miou_eval(targets[0][\"masks\"],(model(images2)[0][\"masks\"].squeeze(1)>0.5))\n",
    "        tiou3,tcnt3 = mi.miou_eval(targets[0][\"masks\"],(model(images3)[0][\"masks\"].squeeze(1)>0.5))\n",
    "        #print(tiou/tcnt)\n",
    "        #print(\"Txnt: \",tcnt)\n",
    "        del images,targets\n",
    "        iou += tiou\n",
    "        cnt += tcnt\n",
    "        #print(iou/cnt)\n",
    "    print(\"mIoU on test is:\",iou.item()/cnt)\n",
    "    model.train()\n",
    "    return iou.item()/cnt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset11\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "class MMCellDataset(Dataset):\n",
    "    def __init__(self,root_dir, tester = False, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.img = []\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.dev = [0.229, 0.224, 0.225]\n",
    "        self.normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "        self.nml = []\n",
    "        self.tester = tester\n",
    "        self.datano =  root_dir.split('/')[1]\n",
    "        print(self.datano)\n",
    "        for im_name in os.listdir(self.root_dir):\n",
    "            self.nml.append(im_name)\n",
    "            # tmplist = []\n",
    "            # lent = len(im_name[:-4])\n",
    "            # print(im_name,im_name[:lent])\n",
    "            # imgtmp = cv2.imread(self.root_dir+im_name,1).transpose(2,0,1)\n",
    "            # tmplist.append(imgtmp[0])\n",
    "            # tmplist.append(imgtmp[1])\n",
    "            # tmplist.append(imgtmp[2])\n",
    "            # for gt_name in os.listdir(\"../\"+self.datano+\"/ground_truths\"):\n",
    "            #     if gt_name[0:0+lent]==im_name[:lent] and gt_name[0+lent]==\"_\":\n",
    "            #         mask = np.array(cv2.imread(\"../\"+self.datano+\"/ground_truths/\"+gt_name,0))\n",
    "            #         tmplist.append(mask)\n",
    "            # tmplist = np.array(tmplist)\n",
    "            # #print(tmplist.shape)\n",
    "            # self.img.append(tmplist)   \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len([name for name in os.listdir(self.root_dir)])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        im_name = self.nml[idx]\n",
    "        tmplist = []\n",
    "        lent = len(im_name[:-4])\n",
    "        #print(im_name,im_name[:lent])\n",
    "        imgtmp = cv2.imread(self.root_dir+im_name,1).transpose(2,0,1)\n",
    "        # scale_percent = 100 # percent of original size\n",
    "        # width = int(imgtmp.shape[1] * scale_percent / 100)\n",
    "        # height = int(imgtmp.shape[0] * scale_percent / 100)\n",
    "        # dim = (width, height)\n",
    "        # imgtmp = cv2.resize(imgtmp, dim, interpolation = cv2.INTER_AREA)\n",
    "        #cv2.imwrite(\"./result1.png\",imgtmp.transpose(1,2,0))\n",
    "        tmplist.append(imgtmp[0])\n",
    "        tmplist.append(imgtmp[1])\n",
    "        tmplist.append(imgtmp[2])\n",
    "        masker = np.zeros(imgtmp[0].shape)\n",
    "        for gt_name in os.listdir(\"../\"+self.datano+\"/ground_truths\"):\n",
    "            if gt_name[0:0+lent]==im_name[:lent] and gt_name[0+lent]==\"_\":\n",
    "                mask = np.array(cv2.imread(\"../\"+self.datano+\"/ground_truths/\"+gt_name,0))\n",
    "                masker+=mask*5\n",
    "                tmplist.append(mask)\n",
    "        tmplist = np.array(tmplist)\n",
    "        #print(masker.shape,type(masker))\n",
    "        masker = np.minimum(masker,255).astype(np.uint8)\n",
    "        #print(masker)\n",
    "        #print(cv2.imwrite(\"./result.png\",np.array([masker]).transpose(1,2,0)))\n",
    "        #print(\"Tmplist: \",tmplist.shape)\n",
    "        patch_stack = tmplist\n",
    "        patch_stack = np.array(patch_stack)\n",
    "        k_w = random.randint(700,patch_stack.shape[2])\n",
    "        k_h = random.randint(700,patch_stack.shape[1])\n",
    "        # k_w = patch_stack.shape[2]\n",
    "        # k_h = patch_stack.shape[1]\n",
    "        o_w = random.randint(0,patch_stack.shape[2]-k_w)\n",
    "        o_h = random.randint(0,patch_stack.shape[1]-k_h)\n",
    "        patch_img = patch_stack[0:3,o_h:o_h+k_h,o_w:o_w+k_w]\n",
    "        patch_img = cv2.cvtColor(patch_img.transpose(1,2,0), cv2.COLOR_BGR2LAB ).transpose(2,0,1)\n",
    "        instances = patch_stack[3:,o_h:o_h+k_h,o_w:o_w+k_w]\n",
    "        instances = instances.transpose(1,2,0)\n",
    "        data = {}\n",
    "        masks = []\n",
    "        boxes = []\n",
    "        area = []\n",
    "        t=0\n",
    "        for a in range(instances.shape[2]):\n",
    "            dispim = instances[:,:,a]\n",
    "            if np.all(dispim == 0):\n",
    "                continue\n",
    "            x,y,w,h = cv2.boundingRect(dispim)\n",
    "            boxes.append([x, y, x+w, y+h])\n",
    "            area.append(torch.tensor(h*w))\n",
    "            masks.append(dispim/255)\n",
    "            t=1\n",
    "        if t==0:\n",
    "            #print(\"Abort\")\n",
    "            if self.tester:\n",
    "                return \"Problem\",\"Hao gai\"\n",
    "            else:\n",
    "                #print(\"Abort Abort \")\n",
    "                return self.__getitem__((idx+1)%len(self.nml))\n",
    "        masks = np.array(masks)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "        img = torch.as_tensor(patch_img, dtype=torch.float32)\n",
    "        img = img/255\n",
    "        img = self.normalize(img)\n",
    "        data[\"boxes\"] =  boxes\n",
    "        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "        data[\"iscrowd\"] = iscrowd\n",
    "        data[\"labels\"] =  torch.ones((boxes.shape[0],), dtype=torch.int64)   # there is only one class\n",
    "        data[\"masks\"] = masks\n",
    "        data[\"area\"] = area\n",
    "        data[\"image_id\"] = torch.tensor(idx)\n",
    "        return img,data\n",
    "# train = MMCellDataset(\"../bigW/images/\")\n",
    "# train1 = MMCellDataset(\"../dataset1/test/\")\n",
    "# train1 = MMCellDataset(\"../dataset1/images/\")\n",
    "train = MMCellDataset(\"../dataset11/images/\")\n",
    "#test = MMCellDataset(\"../dataset12/test/\")\n",
    "fintest = MMCellDataset(\"../test/images/\",True)\n",
    "# train = torch.utils.data.ConcatDataset([train, train1])\n",
    "#print(len(test))\n",
    "trainloader = DataLoader(train, batch_size=4, shuffle=True,collate_fn = collate_fn,num_workers=10)\n",
    "#testloader = DataLoader(test, batch_size=1, shuffle=True,collate_fn = collate_fn,num_workers=10)\n",
    "fintestloader = DataLoader(fintest, batch_size=1, shuffle=False,collate_fn = collate_fn,num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alchemy(nn.Module):\n",
    "    def __init__(self,**kwargs) -> None:\n",
    "        super(alchemy, self).__init__()\n",
    "        self.vis = False\n",
    "        self.maskrcnn = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT,trainable_backbone_layers=4,**kwargs)\n",
    "        in_features = self.maskrcnn.roi_heads.box_predictor.cls_score.in_features  # get number of input features for the classifier\n",
    "        self.maskrcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes=2)  # replace the pre-trained head with a new one\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        ret = self.maskrcnn(images,targets)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torchvision.models.detection.backbone_utils import _resnet_fpn_extractor\n",
    "class alchemy2(nn.Module):\n",
    "    def __init__(self,**kwargs) -> None:\n",
    "        super(alchemy2, self).__init__()\n",
    "        self.vis = False\n",
    "        self.maskrcnn = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT,trainable_backbone_layers=4,**kwargs)\n",
    "        self.backbone = torchvision.models.resnet101(weights=ResNet101_Weights.DEFAULT )\n",
    "        self.backbone = _resnet_fpn_extractor(self.backbone, 4, norm_layer=nn.BatchNorm2d)\n",
    "        self.maskrcnn.backbone = self.backbone\n",
    "        in_features = self.maskrcnn.roi_heads.box_predictor.cls_score.in_features  # get number of input features for the classifier\n",
    "        self.maskrcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes=2)  # replace the pre-trained head with a new one\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        ret = self.maskrcnn(images,targets)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alchemy()\n",
    "model.to(device)\n",
    "#model.load_state_dict(torch.load(\"alchemy_0_9146_d4.torch\"))\n",
    "#model.load_state_dict(torch.load(\"alchemy_0_9116.torch\"))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=8e-5)\n",
    "model.train()\n",
    "lmbda = lambda epoch: 0.1\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30): \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images, targets = data\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        #print(targets[0][\"boxes\"].shape)\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        del images,targets\n",
    "        print(i,'loss:', losses.item())\n",
    "    \n",
    "    torch.save(model.state_dict(), \"alchemy_\"+str(epoch)+\".torch\")\n",
    "    #scheduler.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    #evaluate(model, testloader, device=device)\n",
    "    iou = 0\n",
    "    cnt = 0\n",
    "    \n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        images, targets = data\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        #print(type(model(images)[0][\"masks\"]))\n",
    "        tiou,tcnt = mi.miou_eval(targets[0][\"masks\"],(model(images)[0][\"masks\"].squeeze(1)>0.5))\n",
    "        del images,targets\n",
    "        iou += tiou\n",
    "        cnt += tcnt\n",
    "    print(\"mIoU on val is:\",iou.item()/cnt)\n",
    "\n",
    "    if epoch%1==0:\n",
    "            model.eval()\n",
    "            iou = 0\n",
    "            cnt = 0\n",
    "            for i, data in enumerate(fintestloader, 0):\n",
    "                images, targets = data\n",
    "                #print(type(targets))\n",
    "                if(images[0]==\"Problem\"):\n",
    "                    continue\n",
    "                #print(type(images[0]))\n",
    "                images = list(image.to(device) for image in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                #print(model(images)[0][\"masks\"].squeeze().shape,targets[0][\"masks\"].shape)\n",
    "                tiou,tcnt = mi.miou_eval(targets[0][\"masks\"],(model(images)[0][\"masks\"].squeeze(1)>0.5))\n",
    "                #print(\"Txnt: \",tcnt)\n",
    "                del images,targets\n",
    "                iou += tiou\n",
    "                cnt += tcnt\n",
    "                #print(iou/cnt)\n",
    "            print(\"mIoU on test is:\",iou.item()/cnt)\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "iou = 0\n",
    "cnt = 0\n",
    "for i, data in enumerate(fintestloader, 0):\n",
    "    images, targets = data\n",
    "    #print(type(targets))\n",
    "    if(images[0]==\"Problem\"):\n",
    "        continue\n",
    "    #print(type(images[0]))\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    #print(model(images)[0][\"masks\"].squeeze().shape,targets[0][\"masks\"].shape)\n",
    "    tiou,tcnt = mi.miou_eval(targets[0][\"masks\"],(model1(images)[0][\"masks\"].squeeze(1)>0.5))\n",
    "    #print(\"Txnt: \",tcnt)\n",
    "    del images,targets\n",
    "    iou += tiou\n",
    "    cnt += tcnt\n",
    "#print(iou/cnt)\n",
    "print(\"mIoU on test is:\",iou.item()/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alchemy(box_nms_thresh=0.5)\n",
    "model.to('cuda')\n",
    "model.load_state_dict(torch.load(\"./alchemy_0_0.9317_d20.torch\"))\n",
    "model.eval()\n",
    "#model1 = model\n",
    "for im_name in os.listdir(\"./submission/x/\"):\n",
    "    imgtmp = cv2.imread(\"./submission/x/\"+im_name,1)\n",
    "    imgtmp = cv2.cvtColor(imgtmp, cv2.COLOR_BGR2LAB ).transpose(2,0,1)\n",
    "    imgtmp = torch.as_tensor(imgtmp, dtype=torch.float32)\n",
    "    imgtmp = imgtmp/255\n",
    "    imgtmp = imgtmp.to(device)\n",
    "    output = model([imgtmp])\n",
    "    prefix = im_name[0:-4]\n",
    "    ref = 0\n",
    "    for i in range(output[0]['masks'].shape[0]):\n",
    "        print(output[0]['scores'][i].item())\n",
    "        it = torch.clone(output[0]['masks'][i])\n",
    "        it = it.detach().to('cpu').numpy()\n",
    "        it = it.squeeze(0)\n",
    "        it = (it>=0.5).astype(float)\n",
    "        it = it*255\n",
    "        cv2.imwrite(\"./submission/y/\"+prefix+\"_\"+str(i)+\".bmp\",it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! make sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = set()\n",
    "for im_name in os.listdir('./submission/y/'):\n",
    "    if(im_name[4]!='.'):\n",
    "        test.add(im_name[0:4])\n",
    "\n",
    "print(len(test))\n",
    "print(test)\n",
    "\n",
    "test = set()\n",
    "for im_name in os.listdir('./submission/x/'):\n",
    "    test.add(im_name[0:4])\n",
    "\n",
    "print(len(test))\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alchemy()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"./alchemy_7_0.9183.torch\"))\n",
    "torch.save(model.maskrcnn.backbone.state_dict(),\"./resnet_0.9183.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 2.889272928237915\n",
      "1 loss: 2.142735481262207\n",
      "2 loss: 1.9186341762542725\n",
      "3 loss: 1.6510980129241943\n",
      "4 loss: 1.8573025465011597\n",
      "5 loss: 1.1198457479476929\n",
      "6 loss: 1.140470027923584\n",
      "7 loss: 1.0378395318984985\n",
      "8 loss: 0.967262327671051\n",
      "9 loss: 0.7411631345748901\n",
      "10 loss: 0.8660396933555603\n",
      "11 loss: 0.7378925681114197\n",
      "12 loss: 0.6820128560066223\n",
      "13 loss: 0.7641640901565552\n",
      "14 loss: 0.5853605270385742\n",
      "15 loss: 0.5284894704818726\n",
      "16 loss: 0.5999065041542053\n",
      "17 loss: 0.49230310320854187\n",
      "18 loss: 0.535049319267273\n",
      "19 loss: 0.6601464748382568\n",
      "20 loss: 0.6186835169792175\n",
      "21 loss: 0.5038853883743286\n",
      "22 loss: 0.46592313051223755\n",
      "23 loss: 0.765199601650238\n",
      "24 loss: 0.7244481444358826\n",
      "25 loss: 0.4530074894428253\n",
      "26 loss: 0.41767486929893494\n",
      "27 loss: 0.47089797258377075\n",
      "28 loss: 0.4143081605434418\n",
      "29 loss: 0.3950876295566559\n",
      "30 loss: 0.4874890446662903\n",
      "31 loss: 0.36276811361312866\n",
      "32 loss: 0.41996967792510986\n",
      "33 loss: 0.379890501499176\n",
      "34 loss: 0.4272792935371399\n",
      "35 loss: 1.242864966392517\n",
      "36 loss: 0.5324741005897522\n",
      "37 loss: 0.7469696402549744\n",
      "38 loss: 0.4600636959075928\n",
      "39 loss: 0.3772622048854828\n",
      "40 loss: 0.3238251805305481\n",
      "41 loss: 0.26593711972236633\n",
      "42 loss: 0.4528006315231323\n",
      "43 loss: 0.4881024956703186\n",
      "44 loss: 0.39941009879112244\n",
      "45 loss: 0.36957409977912903\n",
      "46 loss: 0.3324183523654938\n",
      "47 loss: 0.2899380922317505\n",
      "48 loss: 0.28000012040138245\n",
      "49 loss: 0.35935908555984497\n",
      "50 loss: 0.3498716950416565\n",
      "51 loss: 0.8258906602859497\n",
      "52 loss: 0.47830983996391296\n",
      "53 loss: 0.4192374646663666\n",
      "54 loss: 0.5189858078956604\n",
      "55 loss: 0.3499007523059845\n",
      "56 loss: 0.43751928210258484\n",
      "57 loss: 0.4583747982978821\n",
      "58 loss: 0.41224828362464905\n",
      "59 loss: 0.2142830640077591\n",
      "mIoU on test is: 0.8896274869404142\n",
      "0 loss: 0.31050652265548706\n",
      "1 loss: 0.24655994772911072\n",
      "2 loss: 0.3040359616279602\n",
      "3 loss: 0.38733530044555664\n",
      "4 loss: 0.3599977195262909\n",
      "5 loss: 0.34997129440307617\n",
      "6 loss: 0.22930429875850677\n",
      "7 loss: 0.3462311029434204\n",
      "8 loss: 0.2507537603378296\n",
      "9 loss: 0.22728051245212555\n",
      "10 loss: 0.5129673480987549\n",
      "11 loss: 0.4442857503890991\n",
      "12 loss: 0.40023523569107056\n",
      "13 loss: 0.28884705901145935\n",
      "14 loss: 0.24074377119541168\n",
      "15 loss: 0.29517173767089844\n",
      "16 loss: 0.36930668354034424\n",
      "17 loss: 0.22048480808734894\n",
      "18 loss: 0.26692625880241394\n",
      "19 loss: 0.3371656835079193\n",
      "20 loss: 0.7615033388137817\n",
      "21 loss: 0.38053804636001587\n",
      "22 loss: 0.29706230759620667\n",
      "23 loss: 0.44596725702285767\n",
      "24 loss: 0.46160000562667847\n",
      "25 loss: 0.45641371607780457\n",
      "26 loss: 0.7974528074264526\n",
      "27 loss: 0.5506187677383423\n",
      "28 loss: 0.23549027740955353\n",
      "29 loss: 0.39480334520339966\n",
      "30 loss: 0.4278298318386078\n",
      "31 loss: 0.3628750443458557\n",
      "32 loss: 0.6314922571182251\n",
      "33 loss: 0.3256188631057739\n",
      "34 loss: 0.37607792019844055\n",
      "35 loss: 0.28976941108703613\n",
      "36 loss: 0.5228005647659302\n",
      "37 loss: 0.3492494225502014\n",
      "38 loss: 0.34122633934020996\n",
      "39 loss: 0.3480657935142517\n",
      "40 loss: 0.4093545377254486\n",
      "41 loss: 0.32561078667640686\n",
      "42 loss: 0.35661643743515015\n",
      "43 loss: 0.2957836389541626\n",
      "44 loss: 0.6194942593574524\n",
      "45 loss: 0.5394634008407593\n",
      "46 loss: 0.4892370104789734\n",
      "47 loss: 0.4063132405281067\n",
      "48 loss: 0.3804694414138794\n",
      "49 loss: 0.3812577426433563\n",
      "50 loss: 0.26848798990249634\n",
      "51 loss: 0.3151073455810547\n",
      "52 loss: 0.33356350660324097\n",
      "53 loss: 0.26499587297439575\n",
      "54 loss: 0.8974128365516663\n",
      "55 loss: 0.39218565821647644\n",
      "56 loss: 0.25772055983543396\n",
      "57 loss: 0.29964324831962585\n",
      "58 loss: 0.34309542179107666\n",
      "59 loss: 0.317129522562027\n",
      "mIoU on test is: 0.887275718043914\n",
      "0 loss: 0.5734894275665283\n",
      "1 loss: 0.26857584714889526\n",
      "2 loss: 0.6702481508255005\n",
      "3 loss: 0.2327517569065094\n",
      "4 loss: 1.0256377458572388\n",
      "5 loss: 0.31651461124420166\n",
      "6 loss: 0.26415032148361206\n",
      "7 loss: 0.2745654582977295\n",
      "8 loss: 0.3198302984237671\n",
      "9 loss: 0.32082250714302063\n",
      "10 loss: 0.31923961639404297\n",
      "11 loss: 0.4340372383594513\n",
      "12 loss: 0.28797248005867004\n",
      "13 loss: 0.37152186036109924\n",
      "14 loss: 0.2971231937408447\n",
      "15 loss: 0.31864482164382935\n",
      "16 loss: 0.3736492991447449\n",
      "17 loss: 0.28019240498542786\n",
      "18 loss: 0.37155681848526\n",
      "19 loss: 0.254966139793396\n",
      "20 loss: 0.2529650628566742\n",
      "21 loss: 0.3334729075431824\n",
      "22 loss: 0.22570370137691498\n",
      "23 loss: 0.27643486857414246\n",
      "24 loss: 0.30643823742866516\n",
      "25 loss: 0.37464430928230286\n",
      "26 loss: 0.29995009303092957\n",
      "27 loss: 0.38992831110954285\n",
      "28 loss: 0.32001906633377075\n",
      "29 loss: 0.3389764726161957\n",
      "30 loss: 0.3523201644420624\n",
      "31 loss: 0.2770504355430603\n",
      "32 loss: 0.2344340980052948\n",
      "33 loss: 0.9126983284950256\n",
      "34 loss: 0.2879350185394287\n",
      "35 loss: 0.7913411855697632\n",
      "36 loss: 0.3741239309310913\n",
      "37 loss: 0.2862856090068817\n",
      "38 loss: 0.278805673122406\n",
      "39 loss: 0.41952797770500183\n",
      "40 loss: 0.334342896938324\n",
      "41 loss: 0.5279925465583801\n",
      "42 loss: 0.3110014498233795\n",
      "43 loss: 0.9125206470489502\n",
      "44 loss: 0.3373187780380249\n",
      "45 loss: 0.30108389258384705\n",
      "46 loss: 0.39373978972435\n",
      "47 loss: 0.31781405210494995\n",
      "48 loss: 0.3866584002971649\n",
      "49 loss: 0.3630373775959015\n",
      "50 loss: 0.3536854088306427\n",
      "51 loss: 0.27902016043663025\n",
      "52 loss: 0.5444629192352295\n",
      "53 loss: 0.33041778206825256\n",
      "54 loss: 0.2546110451221466\n",
      "55 loss: 0.2787995934486389\n",
      "56 loss: 0.3476330041885376\n",
      "57 loss: 0.38208165764808655\n",
      "58 loss: 0.3661210536956787\n",
      "59 loss: 0.3020115792751312\n",
      "mIoU on test is: 0.8879930170479085\n",
      "0 loss: 0.2922860383987427\n",
      "1 loss: 0.24843062460422516\n",
      "2 loss: 0.3342898488044739\n",
      "3 loss: 0.2825268507003784\n",
      "4 loss: 0.5047922134399414\n",
      "5 loss: 0.28309866786003113\n",
      "6 loss: 0.2988007962703705\n",
      "7 loss: 0.42559635639190674\n",
      "8 loss: 0.2551361918449402\n",
      "9 loss: 0.32516974210739136\n",
      "10 loss: 0.8192667365074158\n",
      "11 loss: 0.7430025935173035\n",
      "12 loss: 0.2506004571914673\n",
      "13 loss: 0.3036825358867645\n",
      "14 loss: 0.5382049083709717\n",
      "15 loss: 0.24326905608177185\n",
      "16 loss: 0.32614216208457947\n",
      "17 loss: 0.29290011525154114\n",
      "18 loss: 0.28810882568359375\n",
      "19 loss: 0.8850998878479004\n",
      "20 loss: 0.2926810383796692\n",
      "21 loss: 0.39344170689582825\n",
      "22 loss: 0.43813568353652954\n",
      "23 loss: 0.2516802251338959\n",
      "24 loss: 0.39161211252212524\n",
      "25 loss: 0.26583409309387207\n",
      "26 loss: 0.3131476044654846\n",
      "27 loss: 0.26898494362831116\n",
      "28 loss: 0.3084014058113098\n",
      "29 loss: 0.24569706618785858\n",
      "30 loss: 0.6740463376045227\n",
      "31 loss: 0.26301339268684387\n",
      "32 loss: 0.23660632967948914\n",
      "33 loss: 0.31332316994667053\n",
      "34 loss: 0.29312649369239807\n",
      "35 loss: 0.22887293994426727\n",
      "36 loss: 0.22169864177703857\n",
      "37 loss: 0.4364210069179535\n",
      "38 loss: 0.39087167382240295\n",
      "39 loss: 0.402587354183197\n",
      "40 loss: 0.3971564769744873\n",
      "41 loss: 0.24157245457172394\n",
      "42 loss: 0.2670598328113556\n",
      "43 loss: 0.2679744362831116\n",
      "44 loss: 0.41744399070739746\n",
      "45 loss: 0.7605831623077393\n",
      "46 loss: 0.22321414947509766\n",
      "47 loss: 0.33473265171051025\n",
      "48 loss: 0.2572149634361267\n",
      "49 loss: 0.30040043592453003\n",
      "50 loss: 0.23494647443294525\n",
      "51 loss: 0.2780761420726776\n",
      "52 loss: 0.2043464481830597\n",
      "53 loss: 0.21894550323486328\n",
      "54 loss: 0.2962256968021393\n",
      "55 loss: 0.29430902004241943\n",
      "56 loss: 0.3667612373828888\n",
      "57 loss: 0.368492066860199\n",
      "58 loss: 0.3298107981681824\n",
      "59 loss: 0.24551799893379211\n",
      "mIoU on test is: 0.8918087477616315\n",
      "0 loss: 3.1152265071868896\n",
      "1 loss: 2.016319513320923\n",
      "2 loss: 2.203680992126465\n",
      "3 loss: 1.721886157989502\n",
      "4 loss: 1.4527984857559204\n",
      "5 loss: 1.6978625059127808\n",
      "6 loss: 1.1822746992111206\n",
      "7 loss: 1.0339767932891846\n",
      "8 loss: 1.1872155666351318\n",
      "9 loss: 1.0393147468566895\n",
      "10 loss: 0.9119205474853516\n",
      "11 loss: 0.8129139542579651\n",
      "12 loss: 0.9659819602966309\n",
      "13 loss: 0.5977762341499329\n",
      "14 loss: 0.6495987176895142\n",
      "15 loss: 0.6323848366737366\n",
      "16 loss: 0.5485241413116455\n",
      "17 loss: 0.7866849899291992\n",
      "18 loss: 0.5848602652549744\n",
      "19 loss: 0.4675407409667969\n",
      "20 loss: 0.4274553656578064\n",
      "21 loss: 0.40460529923439026\n",
      "22 loss: 0.430669367313385\n",
      "23 loss: 0.36981505155563354\n",
      "24 loss: 0.6288042068481445\n",
      "25 loss: 0.640234112739563\n",
      "26 loss: 0.4940216541290283\n",
      "27 loss: 0.48291221261024475\n",
      "28 loss: 0.405531108379364\n",
      "29 loss: 0.44622859358787537\n",
      "30 loss: 0.3494725525379181\n",
      "31 loss: 0.4456729590892792\n",
      "32 loss: 0.6260126233100891\n",
      "33 loss: 0.5703096985816956\n",
      "34 loss: 0.34409409761428833\n",
      "35 loss: 0.5043749809265137\n",
      "36 loss: 0.6519947052001953\n",
      "37 loss: 0.5931273698806763\n",
      "38 loss: 0.38666754961013794\n",
      "39 loss: 0.44045501947402954\n",
      "40 loss: 0.482696533203125\n",
      "41 loss: 0.45003676414489746\n",
      "42 loss: 0.4527011811733246\n",
      "43 loss: 0.6432886719703674\n",
      "44 loss: 0.39251089096069336\n",
      "45 loss: 0.37548816204071045\n",
      "46 loss: 0.46972858905792236\n",
      "47 loss: 0.3307609260082245\n",
      "48 loss: 0.36309799551963806\n",
      "49 loss: 0.3273516297340393\n",
      "50 loss: 0.351014107465744\n",
      "51 loss: 0.3567095398902893\n",
      "52 loss: 0.41459277272224426\n",
      "53 loss: 0.40064293146133423\n",
      "54 loss: 0.5815433859825134\n",
      "55 loss: 0.2939254641532898\n",
      "56 loss: 0.43130162358283997\n",
      "57 loss: 0.4263405203819275\n",
      "58 loss: 0.3397420048713684\n",
      "59 loss: 0.5893383026123047\n",
      "mIoU on test is: 0.8873769104125249\n",
      "0 loss: 0.4901933968067169\n",
      "1 loss: 0.4715566039085388\n",
      "2 loss: 0.543183445930481\n",
      "3 loss: 0.710997462272644\n",
      "4 loss: 0.25912418961524963\n",
      "5 loss: 0.523736834526062\n",
      "6 loss: 0.3033190667629242\n",
      "7 loss: 0.3186292350292206\n",
      "8 loss: 0.2532006502151489\n",
      "9 loss: 0.4343121349811554\n",
      "10 loss: 0.4041139483451843\n",
      "11 loss: 0.40108567476272583\n",
      "12 loss: 0.328303724527359\n",
      "13 loss: 0.4317638874053955\n"
     ]
    }
   ],
   "source": [
    "min_val = 0.91\n",
    "for iv in range(20):\n",
    "    model = alchemy()\n",
    "    model.to(device)\n",
    "    # model.load_state_dict(torch.load(\"./alchemyi_2_0.9283.torch\"))\n",
    "    # model.maskrcnn.backbone.load_state_dict(torch.load(\"./new_resnet2.0.torch\"))\n",
    "    #model.load_state_dict(torch.load(\"alchemy_0_9116.torch\"))\n",
    "    # lr=0.1\n",
    "    # if(iv>=10==0):\n",
    "    #     lr=6e-5\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01,momentum=0.9,weight_decay=0.00004)\n",
    "    #optimizer = torch.optim.AdamW(model.parameters(), lr=8e-5)\n",
    "    model.train()\n",
    "    lmbda = lambda epoch: 1\n",
    "    scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,200)\n",
    "    for epoch in range(4): \n",
    "        model.train()\n",
    "        lrs = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            lrs+=1\n",
    "            images, targets = data\n",
    "            optimizer.zero_grad()\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            #if losses.item()>=0.2:\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #print(\"lr: \",optimizer.param_groups[0]['lr'])\n",
    "            print(i,'loss:', losses.item())\n",
    "            del images,targets,losses\n",
    "            if lrs==100:\n",
    "                lrs=0\n",
    "                #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 200)\n",
    "                # for param_group in optimizer.param_groups:\n",
    "                #     param_group['lr'] = lr*0.6\n",
    "                #     lr = lr * 0.6\n",
    "                val = evalm(model,fintestloader)\n",
    "                if(val>min_val):\n",
    "                    print(\"saved \",str(i),\" with mIoU:\",val)\n",
    "                    min_val=val\n",
    "                    torch.save(model.state_dict(), \"test_\"+str(iv)+\"_\"+str(val)[0:6]+\"_d20.torch\")\n",
    "        #val = evalm(model,fintestloader)\n",
    "        val = evalm(model,fintestloader)\n",
    "        if(val>min_val):\n",
    "            print(\"saved \",str(i),\" with mIoU:\",val)\n",
    "            min_val=val\n",
    "            torch.save(model.state_dict(), \"test_\"+str(iv)+\"_\"+str(val)[0:6]+\"_d20.torch\")\n",
    "        #torch.save(model.state_dict(), \"alchemy_\"+str(iv)+\".torch\")\n",
    "    #scheduler.step()  \n",
    "        \n",
    "    del model\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val=0.92\n",
    "model = alchemy()\n",
    "model.to(device)\n",
    "#model.load_state_dict(torch.load(\"alchemy_0_9146_d4.torch\"))\n",
    "#model.load_state_dict(torch.load(\"alchemy_0_9116.torch\"))\n",
    "lr=0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1,weight_decay=0.00004)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "model.train()\n",
    "lmbda = lambda epoch: 0.5\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,200)\n",
    "for epoch in range(10): \n",
    "    model.train()\n",
    "    lrs = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        lrs+=1\n",
    "        images, targets = data\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        if losses.item()>=0.20:\n",
    "            losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print(\"lr: \",optimizer.param_groups[0]['lr'])\n",
    "        print(i,'loss:', losses.item())\n",
    "        del images,targets, losses\n",
    "        if lrs==30:\n",
    "            lrs=0\n",
    "            #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 200)\n",
    "            # for param_group in optimizer.param_groups:\n",
    "            #     param_group['lr'] = lr*0.6\n",
    "            #     lr = lr * 0.6\n",
    "            val = evalm(model,fintestloader)\n",
    "            if(val>min_val):\n",
    "                print(\"saved \",str(i),\" with mIoU:\",val)\n",
    "                min_val=val\n",
    "                torch.save(model.state_dict(), \"alchemyi_\"+str(epoch)+\"_\"+str(val)[0:6]+\".torch\")\n",
    "    #val = evalm(model,fintestloader)\n",
    "    scheduler.step()  \n",
    "torch.save(model.state_dict(), \"alchemy_4.torch\")\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "model = alchemy()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"./alchemy_7_0.9183.torch\"))\n",
    "# trad = torch.load(\"./new_resnet1.torch\")\n",
    "# newt = OrderedDict()\n",
    "# for i in trad.keys():\n",
    "#     if(i[0:8]==\"backbone\"):\n",
    "#         newt[\"body.\"+i[9:]] = trad[i]\n",
    "#     else:\n",
    "#         newt[i] = trad[i]\n",
    "model.maskrcnn.backbone.load_state_dict(torch.load(\"./new_resnet1.5.torch\"),strict=True)\n",
    "# torch.save(model.maskrcnn.backbone.state_dict(),\"./resnetfpnnew.torch\")\n",
    "evalm(model,fintestloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fintest[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alchemy()\n",
    "model.load_state_dict(torch.load(\"./alchemy_0_0.9317_d20.torch\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "res = model(out)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alchemy()\n",
    "model.load_state_dict(torch.load(\"alchemyi_0_0.9248.torch\"))\n",
    "\n",
    "torch.save(model.maskrcnn.backbone.state_dict(),\"resenter2.1.torch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prakhar_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "603527dc4b5f0cf90dba6785ed8ce1bf41404d422ebeb0779687782e89bf431c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
