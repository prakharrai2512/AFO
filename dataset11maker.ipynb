{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import os\n",
    "import patchify\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.feature_extraction import image as skimg\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN_ResNet50_FPN_V2_Weights\n",
    "import torch.optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.insert(1, '/home/prakharug/AFO')\n",
    "sys.path.insert(1, '/home/prakharug/AFO/pycoco')\n",
    "from pycoco.engine import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_toimage = []\n",
    "\n",
    "for im_name in os.listdir(\"./dataset1/images\"):\n",
    "    tmplist = []\n",
    "    lent = len(im_name[:-4])\n",
    "    print(im_name,im_name[:lent])\n",
    "    imgtmp = cv2.imread(\"./dataset1/images/\"+im_name,1).transpose(2,0,1)\n",
    "    #print(imgtmp[0].shape)\n",
    "    tmplist.append(imgtmp[0])\n",
    "    tmplist.append(imgtmp[1])\n",
    "    tmplist.append(imgtmp[2])\n",
    "    for gt_name in os.listdir(\"./dataset1/ground_truths1\"):\n",
    "        #print(gt_name[10+lent],gt_name[10:10+lent])\n",
    "        if gt_name[10:10+lent]==im_name[:lent] and gt_name[10+lent]==\"_\":\n",
    "            mask = np.array(cv2.imread(\"./dataset1/ground_truths1/\"+gt_name,0))\n",
    "            # mask = (mask > 0).astype(np.uint8) \n",
    "            tmplist.append(mask)\n",
    "    tmplist = np.array(tmplist)\n",
    "    print(tmplist.shape)\n",
    "    instance_toimage.append(tmplist)\n",
    "\n",
    "for im_name in os.listdir(\"./dataset1/test\"):\n",
    "    tmplist = []\n",
    "    lent = len(im_name[:-4])\n",
    "    print(im_name,im_name[:lent])\n",
    "    imgtmp = cv2.imread(\"./dataset1/test/\"+im_name,1).transpose(2,0,1)\n",
    "    #print(imgtmp[0].shape)\n",
    "    tmplist.append(imgtmp[0])\n",
    "    tmplist.append(imgtmp[1])\n",
    "    tmplist.append(imgtmp[2])\n",
    "    for gt_name in os.listdir(\"./dataset1/ground_truths1\"):\n",
    "        #print(gt_name[10+lent],gt_name[10:10+lent])\n",
    "        if gt_name[10:10+lent]==im_name[:lent] and gt_name[10+lent]==\"_\":\n",
    "            mask = np.array(cv2.imread(\"./dataset1/ground_truths1/\"+gt_name,0))\n",
    "            # mask = (mask > 0).astype(np.uint8) \n",
    "            tmplist.append(mask)\n",
    "    tmplist = np.array(tmplist)\n",
    "    print(tmplist.shape)\n",
    "    instance_toimage.append(tmplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_toimage1 = []\n",
    "\n",
    "for im_name in os.listdir(\"./dataset1/images\"):\n",
    "    tmplist = []\n",
    "    lent = len(im_name[:-4])\n",
    "    print(im_name,im_name[:lent])\n",
    "    imgtmp = cv2.imread(\"./dataset1/images/\"+im_name,1).transpose(2,0,1)\n",
    "    #print(imgtmp[0].shape)\n",
    "    tmplist.append(imgtmp[0])\n",
    "    tmplist.append(imgtmp[1])\n",
    "    tmplist.append(imgtmp[2])\n",
    "    for gt_name in os.listdir(\"./dataset1/gt2\"):\n",
    "        #print(gt_name[10+lent],gt_name[10:10+lent])\n",
    "        if gt_name[0:0+lent]==im_name[:lent] and gt_name[0+lent]==\"_\":\n",
    "            mask = np.array(cv2.imread(\"./dataset1/gt2/\"+gt_name,0))\n",
    "            # mask = (mask > 0).astype(np.uint8) \n",
    "            tmplist.append(mask)\n",
    "    tmplist = np.array(tmplist)\n",
    "    print(tmplist.shape)\n",
    "    instance_toimage1.append(tmplist)\n",
    "\n",
    "for im_name in os.listdir(\"./dataset1/test\"):\n",
    "    tmplist = []\n",
    "    lent = len(im_name[:-4])\n",
    "    print(im_name,im_name[:lent])\n",
    "    imgtmp = cv2.imread(\"./dataset1/test/\"+im_name,1).transpose(2,0,1)\n",
    "    #print(imgtmp[0].shape)\n",
    "    tmplist.append(imgtmp[0])\n",
    "    tmplist.append(imgtmp[1])\n",
    "    tmplist.append(imgtmp[2])\n",
    "    for gt_name in os.listdir(\"./dataset1/gt2\"):\n",
    "        #print(gt_name[10+lent],gt_name[10:10+lent])\n",
    "        if gt_name[0:0+lent]==im_name[:lent] and gt_name[0+lent]==\"_\":\n",
    "            mask = np.array(cv2.imread(\"./dataset1/gt2/\"+gt_name,0))\n",
    "            # mask = (mask > 0).astype(np.uint8) \n",
    "            tmplist.append(mask)\n",
    "    tmplist = np.array(tmplist)\n",
    "    print(tmplist.shape)\n",
    "    instance_toimage1.append(tmplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_img = []\n",
    "j = 1\n",
    "for mksl in instance_toimage1:\n",
    "    #print(len(mksl))\n",
    "    for mksin in range(3,len(mksl)):\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.WithHueAndSaturation([\n",
    "            iaa.WithChannels(0, iaa.Add((-30, 30))),\n",
    "            iaa.WithChannels(1, [\n",
    "                iaa.Multiply((0.75, 1.25)),\n",
    "                iaa.LinearContrast((0.75, 1.25))\n",
    "                ])\n",
    "            ])\n",
    "            ,\n",
    "            ])\n",
    "        x,y,w,h = cv2.boundingRect(mksl[mksin])\n",
    "        if x*y*w*h==0 or abs(x+w-mksl.shape[2])<=50 or abs(y+h-mksl.shape[1])<=50:\n",
    "            print(\"bruh\")\n",
    "            continue\n",
    "        else:\n",
    "            #nucleus==40 and cyto==20\n",
    "            stck1 = mksl[0]*(mksl[mksin]==20)\n",
    "            stck2 = mksl[1]*(mksl[mksin]==20)\n",
    "            stck3 = mksl[2]*(mksl[mksin]==20)\n",
    "            stck11 = mksl[0]*(mksl[mksin]==40)\n",
    "            stck21 = mksl[1]*(mksl[mksin]==40)\n",
    "            stck31 = mksl[2]*(mksl[mksin]==40)\n",
    "            print(stck1.shape)\n",
    "            new_img_cyto = np.array([stck1,stck2,stck3],np.uint8)[:,y:y+h,x:x+w]\n",
    "            new_img_nuc = np.array([stck11,stck21,stck31],np.uint8)[:,y:y+h,x:x+w]\n",
    "            print(new_img_cyto.shape)\n",
    "            new_img_cyto = seq(images = [new_img_cyto.transpose(1,2,0)])[0].transpose(2,0,1)\n",
    "            new_img_nuc = seq(images = [new_img_nuc.transpose(1,2,0)])[0].transpose(2,0,1)\n",
    "            new_img = new_img_cyto+new_img_nuc\n",
    "            cell_img.append(new_img)\n",
    "            #cv2.imwrite('./jsr'+str(j)+'.png',new_img.transpose(1,2,0))\n",
    "            j+=1\n",
    "            #break\n",
    "            #cv2.waitkey(0)\n",
    "            #cv2.destroyAllindows\n",
    "\n",
    "for mksl in instance_toimage1:\n",
    "    #print(len(mksl))\n",
    "    for mksin in range(3,len(mksl)):\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.WithHueAndSaturation([\n",
    "            iaa.WithChannels(0, iaa.Add((-30, 30))),\n",
    "            iaa.WithChannels(1, [\n",
    "                iaa.Multiply((0.75, 1.25)),\n",
    "                iaa.LinearContrast((0.75, 1.25))\n",
    "                ])\n",
    "            ])\n",
    "            ,\n",
    "            ])\n",
    "        x,y,w,h = cv2.boundingRect(mksl[mksin])\n",
    "        if x*y*w*h==0 or abs(x+w-mksl.shape[2])<=50 or abs(y+h-mksl.shape[1])<=50:\n",
    "            print(\"bruh\")\n",
    "            continue\n",
    "        else:\n",
    "            #nucleus==40 and cyto==20\n",
    "            stck1 = mksl[0]*(mksl[mksin]==20)\n",
    "            stck2 = mksl[1]*(mksl[mksin]==20)\n",
    "            stck3 = mksl[2]*(mksl[mksin]==20)\n",
    "            stck11 = mksl[0]*(mksl[mksin]==40)\n",
    "            stck21 = mksl[1]*(mksl[mksin]==40)\n",
    "            stck31 = mksl[2]*(mksl[mksin]==40)\n",
    "            print(stck1.shape)\n",
    "            new_img_cyto = np.array([stck1,stck2,stck3],np.uint8)[:,y:y+h,x:x+w]\n",
    "            new_img_nuc = np.array([stck11,stck21,stck31],np.uint8)[:,y:y+h,x:x+w]\n",
    "            print(new_img_cyto.shape)\n",
    "            new_img_cyto = seq(images = [new_img_cyto.transpose(1,2,0)])[0].transpose(2,0,1)\n",
    "            new_img_nuc = seq(images = [new_img_nuc.transpose(1,2,0)])[0].transpose(2,0,1)\n",
    "            new_img = new_img_cyto+new_img_nuc\n",
    "            cell_img.append(new_img)\n",
    "            #cv2.imwrite('./jsr'+str(j)+'.png',new_img.transpose(1,2,0))\n",
    "            j+=1\n",
    "            #break\n",
    "            #cv2.waitkey(0)\n",
    "            #cv2.destroyAllindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cell_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_non_transparent(face_img, overlay_img):\n",
    "    # Let's find a mask covering all the non-black (foreground) pixels\n",
    "    # NB: We need to do this on grayscale version of the image\n",
    "    #print(\"overlay img \",overlay_img.shape)\n",
    "    gray_overlay = cv2.cvtColor(overlay_img, cv2.COLOR_BGR2GRAY)\n",
    "    overlay_mask = cv2.threshold(gray_overlay, 1, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Let's shrink and blur it a little to make the transitions smoother...\n",
    "    #overlay_mask = cv2.erode(overlay_mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n",
    "    #overlay_mask = cv2.blur(overlay_mask, (3, 3))\n",
    "\n",
    "    # And the inverse mask, that covers all the black (background) pixels\n",
    "    background_mask = (255) - overlay_mask\n",
    "\n",
    "    # Turn the masks into three channel, so we can use them as weights\n",
    "    overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
    "    background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Create a masked out face image, and masked out overlay\n",
    "    # We convert the images to floating point in range 0.0 - 1.0\n",
    "    face_part = (face_img * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
    "    overlay_part = (overlay_img * (1 / 255.0)) * (overlay_mask * (1 / 255.0))\n",
    "\n",
    "    # And finally just add them together, and rescale it back to an 8bit integer image\n",
    "    return np.uint8(cv2.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "lob = 1000\n",
    "for iml in instance_toimage:\n",
    "    cv2.imwrite(\"./dataset2.1/images/\"+str(lob)+'.png',iml[0:3].transpose(1,2,0))\n",
    "    for k in range(0,iml.shape[0]-3):\n",
    "        cv2.imwrite(\"./dataset2.1/ground_truths/\"+str(lob)+'_'+str(k+1)+'.png',np.array([iml[k+3]]).transpose(1,2,0))\n",
    "    lob+=1\n",
    "    i=0\n",
    "    broke = 0\n",
    "    if(iml.shape[0]<=5):\n",
    "        continue\n",
    "    while i<=1 and broke<=6:\n",
    "        i+=1\n",
    "        broke+=1\n",
    "        tmpl = iml.copy()\n",
    "        cnt=0\n",
    "        if cnt>=6:\n",
    "            break\n",
    "        for j in range(0,20):\n",
    "            paster = False\n",
    "            idx = random.randint(0,len(cell_img)-1)\n",
    "            rtrnd=random.randint(0,4)\n",
    "            flipr = random.randint(0,1)\n",
    "            flipu = random.randint(0,1)\n",
    "            seq = iaa.Sequential([\n",
    "            iaa.WithHueAndSaturation([\n",
    "            iaa.WithChannels(0, iaa.Add((-15, 15))),\n",
    "            iaa.WithChannels(1, [\n",
    "                iaa.Multiply((0.85, 1.15)),\n",
    "                iaa.LinearContrast((0.85, 1.15))\n",
    "                ])\n",
    "            ])\n",
    "            ,\n",
    "            iaa.Rot90((rtrnd), keep_size=False),\n",
    "            iaa.Fliplr(flipr),\n",
    "            iaa.Flipud(flipu),\n",
    "            ])\n",
    "\n",
    "            # print(cell_img[idx].shape)\n",
    "            test = cell_img[idx].transpose(1,2,0)\n",
    "            cell_paste = seq(images=[test])\n",
    "            cell_paste = cell_paste[0].transpose(2,0,1)\n",
    "            #cell_paste = cell_img[idx]\n",
    "            k_w = cell_paste.shape[2]\n",
    "            k_h = cell_paste.shape[1]\n",
    "            tryer=0\n",
    "            o_w=0\n",
    "            o_h=0\n",
    "            while paster==False and tryer<=5:\n",
    "                tryer+=1\n",
    "                o_w = random.randint(0,tmpl.shape[2]-k_w)\n",
    "                o_h = random.randint(0,tmpl.shape[1]-k_h)\n",
    "                patch_img = tmpl[0:3,o_h:o_h+k_h,o_w:o_w+k_w]\n",
    "                instances = tmpl[3:,o_h:o_h+k_h,o_w:o_w+k_w]\n",
    "                instances = instances.transpose(1,2,0)\n",
    "                for a in range(instances.shape[2]):\n",
    "                    dispim = instances[:,:,a]\n",
    "                    #cv2.imwrite('writer.jpg',dispim)\n",
    "                    if np.all(dispim == 0):\n",
    "                        paster = True\n",
    "                        continue\n",
    "                    else:\n",
    "                        paster=False\n",
    "                        break\n",
    "                    \n",
    "            if paster==True:\n",
    "                back = np.zeros([3,tmpl.shape[1],tmpl.shape[2]],np.uint8)\n",
    "                back[:,o_h:o_h+k_h,o_w:o_w+k_w] = cell_paste\n",
    "                grao = cv2.cvtColor(back.transpose(1,2,0), cv2.COLOR_BGR2GRAY)\n",
    "                grao = (grao>0)*255\n",
    "                grao = np.array([grao])\n",
    "                #print(cell_paste.shape,k_h)\n",
    "                #cv2.imwrite('jsr.png',tmpl[0:3].transpose(1,2,0))\n",
    "                #print(type(tmpl[0:3]),type(back))\n",
    "                tmpl[0:3] = blend_non_transparent(tmpl[0:3].transpose(1,2,0),back.transpose(1,2,0)).transpose(2,0,1)\n",
    "                #cv2.imwrite('jsr.png',tmpl[0:3].transpose(1,2,0))\n",
    "                #cv2.imwrite('comp.png',cell_paste.transpose(1,2,0))\n",
    "                #print(tmpl.shape,grao.shape)\n",
    "                tmpl = np.append(tmpl,grao,0)\n",
    "                #print(tmpl.shape,grao.shape)\n",
    "                cnt+=1\n",
    "        if cnt>=3:\n",
    "            print('hello')\n",
    "            cv2.imwrite(\"./dataset11/images/\"+str(lob)+'.png',tmpl[0:3].transpose(1,2,0))\n",
    "            for k in range(0,tmpl.shape[0]-3):\n",
    "                cv2.imwrite(\"./dataset11/ground_truths/\"+str(lob)+'_'+str(k+1)+'.png',np.array([tmpl[k+3]]).transpose(1,2,0))\n",
    "            lob+=1\n",
    "        else:\n",
    "            i-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_name in os.listdir(\"./submission/images\"):\n",
    "    tmplist = []\n",
    "    lent = len(im_name[:-4])\n",
    "    print(im_name,im_name[:lent])\n",
    "    imgtmp = cv2.imread(\"./submission/images/\"+im_name,1)\n",
    "    imgtmp = (imgtmp > 0)*255\n",
    "    cv2.imwrite(\"./submission/x/\"+im_name[0:-4]+\".png\",imgtmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_name in os.listdir(\"./test/images2\"):\n",
    "    tmplist = []\n",
    "    lent = len(im_name[:-4])\n",
    "    print(im_name,im_name[:lent])\n",
    "    imgtmp = cv2.imread(\"./test/images2/\"+im_name,1)\n",
    "    #imgtmp = (imgtmp > 0)*255\n",
    "    cv2.imwrite(\"./test/images/\"+im_name[0:-4]+\".png\",imgtmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_name in os.listdir(\"./dataset1/ground_truths1\"):\n",
    "    tmplist = []\n",
    "    lent = len(im_name[10:-4])\n",
    "    print(im_name,im_name[10:-4])\n",
    "    imgtmp = cv2.imread(\"./dataset1/ground_truths1/\"+im_name,1)\n",
    "    #imgtmp = (imgtmp > 0)*255\n",
    "    cv2.imwrite(\"./dataset1/ground_truths/\"+im_name[10:-4]+\".png\",imgtmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('prakhar_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "603527dc4b5f0cf90dba6785ed8ce1bf41404d422ebeb0779687782e89bf431c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
