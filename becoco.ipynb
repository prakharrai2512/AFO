{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "from itertools import groupby\n",
    "import os\n",
    "import patchify\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.feature_extraction import image as skimg\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN_ResNet50_FPN_V2_Weights,MaskRCNN_ResNet50_FPN_Weights\n",
    "import torch.optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.insert(1, '/home/prakharug/AFO')\n",
    "sys.path.insert(1, '/home/prakharug/AFO/pycoco')\n",
    "from pycoco.engine import train_one_epoch, evaluate\n",
    "import miou_eval as mi\n",
    "import json\n",
    "import numpy as np\n",
    "from pycocotools import mask\n",
    "from skimage import measure\n",
    "import help_lo as hlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskers(ground_truth_binary_mask):\n",
    "    fortran_ground_truth_binary_mask = np.asfortranarray(ground_truth_binary_mask)\n",
    "    encoded_ground_truth = mask.encode(fortran_ground_truth_binary_mask)\n",
    "    ground_truth_area = mask.area(encoded_ground_truth)\n",
    "    ground_truth_bounding_box = mask.toBbox(encoded_ground_truth)\n",
    "    contours = measure.find_contours(ground_truth_binary_mask, 0.5)\n",
    "    #contour = np.flip(contour, axis=1)\n",
    "    return ground_truth_area,ground_truth_bounding_box,contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    {'id': 1, 'name': 'cell'},{'id':2,'name':'none'}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_mask_to_rle(binary_mask):\n",
    "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
    "    counts = rle.get('counts')\n",
    "    for i, (value, elements) in enumerate(groupby(binary_mask.ravel(order='F'))):\n",
    "        if i == 0 and value == 1:\n",
    "            counts.append(0)\n",
    "        counts.append(len(list(elements)))\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for imname in os.listdir('./dataset1/images/'):\n",
    "    dt  = {}\n",
    "    dt['file_name'] = imname\n",
    "    dt['id'] = int(imname.split('.')[0])\n",
    "    imgt = cv2.imread('./dataset1/images/'+imname)\n",
    "    dt['height']  = imgt.shape[0]\n",
    "    dt['width']  = imgt.shape[1]\n",
    "    images.append(dt)\n",
    "    #print(imgt.shape)\n",
    "for imname in os.listdir('./dataset1/test/'):\n",
    "    dt  = {}\n",
    "    dt['file_name'] = imname\n",
    "    dt['id'] = int(imname.split('.')[0])\n",
    "    imgt = cv2.imread('./dataset1/test/'+imname)\n",
    "    dt['height']  = imgt.shape[0]\n",
    "    dt['width']  = imgt.shape[1]\n",
    "    images.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "annoid = 1\n",
    "bt = 0\n",
    "for imname in os.listdir('./dataset1/ground_truths/'):\n",
    "    print(bt)\n",
    "    bt+=1\n",
    "    dt = {}\n",
    "    tll = []\n",
    "    with np.printoptions(threshold=np.inf):\n",
    "        #print(cv2.imread('./dataset12/ground_truths/'+imname,0))/255\n",
    "        pass\n",
    "    maskt = np.array(cv2.imread('./dataset1/ground_truths/'+imname,0),dtype = np.uint8).squeeze()\n",
    "    #print(maskt.shape)\n",
    "    box2 = cv2.boundingRect(maskt)\n",
    "    area,bbox,poly = maskers(maskt)\n",
    "    # segrl= 0\n",
    "    # segr = []\n",
    "    for contour in poly:\n",
    "        contour = np.flip(contour, axis=1)\n",
    "        segmentation = contour.ravel().tolist()\n",
    "        if(len(segmentation)>20):\n",
    "            segrl = len(segmentation)\n",
    "            segr = segmentation\n",
    "            tll.append(segmentation)\n",
    "        \n",
    "    # if(len(dt[\"segmentation\"])>1):\n",
    "    #     print(\"arre bt\")\n",
    "    #print(poly)\n",
    "    # polt = []\n",
    "    # for ar in poly:\n",
    "    #     polt.append(ar.flatten())\n",
    "    # polt = [polte.tolist() for polte in polt]\n",
    "    bbox = [int(btbox) for btbox in bbox]\n",
    "    \n",
    "    #print(polt)\n",
    "    #print(bbox,area)\n",
    "    #dt['area'] = \n",
    "    #print(poly)\n",
    "    name = imname.split('.')[0]\n",
    "    fname = int(name.split('_')[0])\n",
    "    lname = int(name.split('_')[1])\n",
    "    dt[\"id\"] = annoid\n",
    "    annoid+=1\n",
    "    dt[\"image_id\"] = fname\n",
    "    dt[\"category_id\"] = 1\n",
    "    #dt[\"segmentation\"] = binary_mask_to_rle(maskt)\n",
    "    dt[\"segmentation\"] = hlp.binary_mask_to_polygon(maskt)\n",
    "    dt[\"area\"] = int(area)\n",
    "    dt[\"bbox\"] = bbox\n",
    "    dt[\"iscrowd\"] = 0\n",
    "    annotations.append(dt)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in annotations:\n",
    "    for mk in g[\"segmentation\"]:\n",
    "        print(len(mk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info =  {\n",
    "        \"description\": \"COCO 2017 Dataset\",\n",
    "        \"url\": \"http://cocodataset.org\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2017,\n",
    "        \"contributor\": \"COCO Consortium\",\n",
    "        \"date_created\": \"2017/09/01\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicty = {\"info\" : info, \"images\" : images,\"annotations\" : annotations,\"categories\" : categories} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('result_d4.json', 'w') as fp:\n",
    "    json.dump(dicty, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('prakhar_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "603527dc4b5f0cf90dba6785ed8ce1bf41404d422ebeb0779687782e89bf431c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
