{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import os\n",
    "import patchify\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.feature_extraction import image as skimg\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN_ResNet50_FPN_V2_Weights\n",
    "import torch.optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.insert(1, '/home/prakharug/AFO')\n",
    "sys.path.insert(1, '/home/prakharug/AFO/pycoco')\n",
    "from pycoco.engine import train_one_epoch, evaluate\n",
    "import miou_eval as mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dims(a, start=0, count=2):\n",
    "    \"\"\" Reshapes numpy array a by combining count dimensions, \n",
    "        starting at dimension index start \"\"\"\n",
    "    s = a.shape\n",
    "    return np.reshape(a, s[:start] + (-1,) + s[start+count:])\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMCellDataset(Dataset):\n",
    "    def __init__(self,root_dir, tester = False, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.img = []\n",
    "        self.nml = []\n",
    "        self.tester = tester\n",
    "        self.datano =  root_dir.split('/')[1]\n",
    "        print(self.datano)\n",
    "        for im_name in os.listdir(self.root_dir):\n",
    "            self.nml.append(im_name)\n",
    "            # tmplist = []\n",
    "            # lent = len(im_name[:-4])\n",
    "            # print(im_name,im_name[:lent])\n",
    "            # imgtmp = cv2.imread(self.root_dir+im_name,1).transpose(2,0,1)\n",
    "            # tmplist.append(imgtmp[0])\n",
    "            # tmplist.append(imgtmp[1])\n",
    "            # tmplist.append(imgtmp[2])\n",
    "            # for gt_name in os.listdir(\"../\"+self.datano+\"/ground_truths\"):\n",
    "            #     if gt_name[0:0+lent]==im_name[:lent] and gt_name[0+lent]==\"_\":\n",
    "            #         mask = np.array(cv2.imread(\"../\"+self.datano+\"/ground_truths/\"+gt_name,0))\n",
    "            #         tmplist.append(mask)\n",
    "            # tmplist = np.array(tmplist)\n",
    "            # #print(tmplist.shape)\n",
    "            # self.img.append(tmplist)   \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len([name for name in os.listdir(self.root_dir)])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        im_name = self.nml[idx]\n",
    "        tmplist = []\n",
    "        lent = len(im_name[:-4])\n",
    "        #print(im_name,im_name[:lent])\n",
    "        imgtmp = cv2.imread(self.root_dir+im_name,1).transpose(2,0,1)\n",
    "        tmplist.append(imgtmp[0])\n",
    "        tmplist.append(imgtmp[1])\n",
    "        tmplist.append(imgtmp[2])\n",
    "        for gt_name in os.listdir(\"../\"+self.datano+\"/ground_truths\"):\n",
    "            if gt_name[0:0+lent]==im_name[:lent] and gt_name[0+lent]==\"_\":\n",
    "                mask = np.array(cv2.imread(\"../\"+self.datano+\"/ground_truths/\"+gt_name,0))\n",
    "                tmplist.append(mask)\n",
    "        tmplist = np.array(tmplist)\n",
    "        #print(\"Tmplist: \",tmplist.shape)\n",
    "        patch_stack = tmplist\n",
    "        patch_stack = np.array(patch_stack)\n",
    "        # k_w = random.randint(700,patch_stack.shape[2])\n",
    "        # k_h = random.randint(700,patch_stack.shape[1])\n",
    "        k_w = patch_stack.shape[2]\n",
    "        k_h = patch_stack.shape[1]\n",
    "        o_w = random.randint(0,patch_stack.shape[2]-k_w)\n",
    "        o_h = random.randint(0,patch_stack.shape[1]-k_h)\n",
    "        patch_img = patch_stack[0:3,o_h:o_h+k_h,o_w:o_w+k_w]\n",
    "        image_hsv = cv2.cvtColor(patch_img.transpose(1,2,0), cv2.COLOR_BGR2HSV ).transpose(2,0,1)\n",
    "        image_lab = cv2.cvtColor(patch_img.transpose(1,2,0), cv2.COLOR_BGR2LAB ).transpose(2,0,1)\n",
    "        #print(image_hsv.shape,image_lab.shape)\n",
    "        patch_img = np.concatenate((patch_img,image_hsv,image_lab),0)\n",
    "        #patch_img = cv2.cvtColor(patch_img.transpose(1,2,0), cv2.COLOR_BGR2LAB ).transpose(2,0,1)\n",
    "        instances = patch_stack[3:,o_h:o_h+k_h,o_w:o_w+k_w]\n",
    "        instances = instances.transpose(1,2,0)\n",
    "        data = {}\n",
    "        masks = []\n",
    "        boxes = []\n",
    "        area = []\n",
    "        t=0\n",
    "        sem_mask = np.zeros((instances.shape[0],instances.shape[1]))\n",
    "        for a in range(instances.shape[2]):\n",
    "            dispim = instances[:,:,a]\n",
    "            if np.all(dispim == 0):\n",
    "                continue\n",
    "            x,y,w,h = cv2.boundingRect(dispim)\n",
    "            boxes.append([x, y, x+w, y+h])\n",
    "            area.append(torch.tensor(h*w))\n",
    "            masks.append(dispim/255)\n",
    "            sem_mask += dispim\n",
    "            t=1\n",
    "        if t==0:\n",
    "            #print(\"Abort\")\n",
    "            if self.tester:\n",
    "                return \"Problem\",\"Hao gai\",\"Gais\"\n",
    "            else:\n",
    "                #print(\"Abort Abort \")\n",
    "                return self.__getitem__((idx+1)%len(self.nml))\n",
    "        masks = np.array(masks)\n",
    "        sem_mask = np.array(sem_mask > 0,dtype=np.int32)\n",
    "        #print(sem_mask)\n",
    "        neg_mask = np.array((sem_mask==0),dtype=np.int32)\n",
    "        #print(neg_mask)\n",
    "        #sem_mask_c = torch.as_tensor(sem_mask.sum())\n",
    "        sem_mask = torch.as_tensor(np.array([sem_mask,sem_mask,sem_mask]),dtype=torch.int32)\n",
    "        neg_mask = torch.as_tensor(np.array([neg_mask,neg_mask,neg_mask]),dtype=torch.int32)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "        img = torch.as_tensor(patch_img, dtype=torch.float32)\n",
    "        img = img/255\n",
    "        data[\"boxes\"] =  boxes\n",
    "        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "        data[\"iscrowd\"] = iscrowd\n",
    "        data[\"labels\"] =  torch.ones((boxes.shape[0],), dtype=torch.int64)   # there is only one class\n",
    "        data[\"masks\"] = masks\n",
    "        data[\"area\"] = area\n",
    "        data[\"image_id\"] = torch.tensor(idx)\n",
    "        return img,sem_mask,neg_mask\n",
    "train = MMCellDataset(\"../dataset4/images/\")\n",
    "test = MMCellDataset(\"../dataset4/test/\")\n",
    "fintest = MMCellDataset(\"../test/images/\",True)\n",
    "#train = torch.utils.data.ConcatDataset([train, test])\n",
    "#print(len(test))\n",
    "trainloader = DataLoader(train, batch_size=1, shuffle=True,collate_fn = collate_fn,num_workers=10)\n",
    "testloader = DataLoader(test, batch_size=1, shuffle=True,collate_fn = collate_fn,num_workers=10)\n",
    "fintestloader = DataLoader(fintest, batch_size=1, shuffle=True,collate_fn = collate_fn,num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yesu(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(yesu,self).__init__()\n",
    "        self.channel_trans = nn.Sequential(\n",
    "                nn.Conv2d(9, 128,(1,1),stride=1,padding='same',padding_mode='replicate',bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(128,128,(1,1),stride=1,padding='same',padding_mode='replicate',bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.Conv2d(128,3,(1,1),stride=1,padding='same',padding_mode='replicate',bias=False),\n",
    "                nn.BatchNorm2d(3),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "    \n",
    "    def forward(self,images,sem_mask=None,neg_mask=None):\n",
    "        mean_loss = torch.Tensor([0]).to(device)\n",
    "        dev_loss = torch.Tensor([0]).to(device)\n",
    "        # dev_loss2 = torch.Tensor([0]).to(device) \n",
    "        for ind in range(len(images)):\n",
    "            #print(images.shape)\n",
    "            new_im = self.channel_trans(torch.stack([images[ind]]))\n",
    "            images[ind] = new_im[0]\n",
    "            if self.training:\n",
    "                #print(torch.as_tensor(sem_mask[ind].sum((1,2)).shape))\n",
    "                #print(sem_mask[ind][0:1,].clone().cpu().numpy().transpose(1,2,0).shape)\n",
    "                #cv2.imwrite(\"seg.png\",sem_mask[ind][0:1,].clone().cpu().numpy().transpose(1,2,0)*255)\n",
    "                #neg_mask = (sem_mask==0).to(device)\n",
    "                #print(torch.mul(images[ind],sem_mask[ind]).sum((1,2)))\n",
    "                sem_val = torch.mul(images[ind],sem_mask[ind]).sum((1,2))/torch.as_tensor(sem_mask[ind].sum((1,2)))\n",
    "                neg_val = torch.mul(images[ind],neg_mask[ind]).sum((1,2))/torch.as_tensor(neg_mask[ind].sum((1,2)))\n",
    "                mean_loss += torch.abs(torch.mul(sem_val,neg_val).sum()/(((torch.square(sem_val).sum())**0.5)*((torch.square(neg_val).sum())**0.5)))\n",
    "                dev_loss1 = torch.std(sem_val, axis = 0)#*sem_val.shape[0]/torch.as_tensor(sem_mask[ind].sum())\n",
    "                dev_loss2 = torch.std(neg_val, axis = 0)#*neg_val.shape[0]/torch.as_tensor(neg_mask[ind].sum())\n",
    "                #print(sem_val,neg_val)\n",
    "                \n",
    "                #dev_loss1 = torch.square(torch.mul(images[ind],sem_mask[ind]) - sem_val).sum(1,2)/torch.as_tensor(sem_mask[ind].sum())\n",
    "                #dev_loss2 = torch.square(torch.mul(images[ind],neg_mask[ind]) - neg_val).sum(1,2)/torch.as_tensor(neg_mask[ind].sum())\n",
    "                dev_loss += dev_loss1\n",
    "        if self.training:\n",
    "            return images,mean_loss \n",
    "        else:\n",
    "            return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = yesu()\n",
    "model.to(device)\n",
    "#model.load_state_dict(torch.load('./yesu_0.torch'))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "model.train()\n",
    "lmbda = lambda epoch: 0.1\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30): \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images, targets,negt = data\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = list(targets.to(device) for targets in targets)\n",
    "        negt = list(targets.to(device) for targets in negt)\n",
    "        #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        #print(targets[0][\"boxes\"].shape)\n",
    "        #optimizer.zero_grad()\n",
    "        images,loss = model(images, targets,negt)\n",
    "        #losses = sum(loss for loss in loss_dict.values())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(images[0])\n",
    "        #cv2.imwrite(\"jsr.png\",images[0].detach().cpu().numpy().transpose(1,2,0)*255)\n",
    "        del targets,negt,images\n",
    "        print(i,'loss:', loss.item())\n",
    "    scheduler.step()\n",
    "    torch.save(model.state_dict(), \"yesu_\"+str(epoch)+\".torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"yesu_yesu.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "#model.load_state_dict(torch.load('./yesu_0.torch'))\n",
    "for im_name in os.listdir('../dataset4/images/'):\n",
    "    image_bgr = cv2.imread('../dataset4/images/'+im_name,1).transpose(2,0,1)\n",
    "    #image_bgr = cv2.cvtColor(image_bgr.transpose(1,2,0), cv2.COLOR_BGR2RGB ).transpose(2,0,1)\n",
    "    image_hsv = cv2.cvtColor(image_bgr.transpose(1,2,0), cv2.COLOR_BGR2HSV ).transpose(2,0,1)\n",
    "    #print(image_bgr)\n",
    "    image_lab = cv2.cvtColor(image_bgr.transpose(1,2,0), cv2.COLOR_BGR2LAB ).transpose(2,0,1)\n",
    "    patch_img = np.concatenate((image_bgr,image_hsv,image_lab),0,dtype=np.float32)\n",
    "    patch_img = torch.as_tensor(patch_img,dtype=torch.float32,device=device)/255\n",
    "    print(model([patch_img],None,None)[0].shape)\n",
    "    imgf = model([patch_img],None,None)[0].detach().cpu().numpy().transpose(1,2,0)*255\n",
    "    print(imgf)\n",
    "    #imt = torch.as_tensor([patch_img],dtype=torch.float32,device=device),None,None\n",
    "    cv2.imwrite(\"../dataset4/yesu/test.jpg\",imgf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('prakhar_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "603527dc4b5f0cf90dba6785ed8ce1bf41404d422ebeb0779687782e89bf431c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
